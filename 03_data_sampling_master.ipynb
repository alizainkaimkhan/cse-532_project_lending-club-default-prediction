{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Creating the Master Balanced Sample (Stratified Undersampling)\n",
        "\n",
        "This notebook creates a balanced \"master sample\" dataset. This dataset will be the foundation for training and testing all models.\n",
        "\n",
        "## Strategy: Undersampling the Majority Class\n",
        "\n",
        "The cleaned dataset (`lc_loans_cleaned.csv`) is imbalanced, with far more \"Fully Paid\" loans (target=0) than \"Charged Off\" loans (target=1).\n",
        "\n",
        "To build a model that learns to recognize default, we will create a 1:1 balanced dataset by:\n",
        "1.  Taking **all** observations from the minority class (every \"Charged Off\" loan).\n",
        "2.  Randomly sampling an **equal number** of observations from the majority class (\"Fully Paid\" loans).\n",
        "3.  Combining these two sets into a single, balanced DataFrame.\n",
        "\n",
        "This gives us the largest possible balanced dataset for training and ensures the model sees every single example of a default."
      ],
      "metadata": {
        "id": "q2d5ca7rjpP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "w3hzLZJsifwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration\n",
        "\n",
        "Define the input file (cleaned dataset) and the new output file for the master sample."
      ],
      "metadata": {
        "id": "z5OOcIE9ihHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "# The cleaned dataset from preprocessing\n",
        "INPUT_FILE = 'lc_loans_cleaned.csv'\n",
        "\n",
        "# The new, large, and balanced master sample\n",
        "OUTPUT_FILE = 'lc_loans_master_sample.csv'"
      ],
      "metadata": {
        "id": "56eZY7awijO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load the Cleaned Dataset\n",
        "\n",
        "First, we load the `lc_loans_cleaned.csv` file."
      ],
      "metadata": {
        "id": "OujZGIujilIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    df = pd.read_csv(INPUT_FILE)\n",
        "    print(\"1. Loading the cleaned dataset...\")\n",
        "    print(f\"   - Shape of the cleaned dataset: {df.shape}\")\n",
        "    print(\"\\n   - Original class distribution:\")\n",
        "    print(df['target'].value_counts())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{INPUT_FILE}' was not found.\")\n",
        "    print(\"Please make sure you've uploaded the file to this Colab session.\")"
      ],
      "metadata": {
        "id": "aqz-S1FHipuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Separate Data into Strata\n",
        "\n",
        "Next, we split the DataFrame into two separate groups, or \"strata,\" based on the target variable."
      ],
      "metadata": {
        "id": "_6XtJCzDislX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# target = 0 -> Fully Paid (majority class)\n",
        "df_majority = df[df['target'] == 0]\n",
        "\n",
        "# target = 1 -> Charged Off (minority class)\n",
        "df_minority = df[df['target'] == 1]\n",
        "\n",
        "print(f\"   - Found {len(df_majority):,} majority class (target=0) loans.\")\n",
        "print(f\"   - Found {len(df_minority):,} minority class (target=1) loans.\")"
      ],
      "metadata": {
        "id": "JSKIUEPdit0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Sample the Majority Class and Combine\n",
        "\n",
        "Now we perform the undersampling. We'll find out how many minority-class observations we have (`N`), and then sample exactly `N` observations from the majority class."
      ],
      "metadata": {
        "id": "iOM3ig7AixIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the size of the minority class\n",
        "N = len(df_minority)\n",
        "\n",
        "print(f\"1. The minority class has {N:,} observations.\")\n",
        "print(f\"2. Sampling {N:,} observations from the majority class...\")\n",
        "\n",
        "# Randomly sample the majority class to match the minority class size\n",
        "df_majority_sampled = df_majority.sample(n=N, random_state=42)\n",
        "\n",
        "print(f\"   - Sampling complete. We now have {len(df_majority_sampled):,} sampled good loans.\")\n",
        "\n",
        "# Combine the full minority DataFrame with the sampled majority DataFrame\n",
        "df_master_sample = pd.concat([df_majority_sampled, df_minority])\n",
        "print(\"\\n3. Combined the two DataFrames.\")"
      ],
      "metadata": {
        "id": "cL0CatTBiyg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Step: Shuffle, Save, and Verify\n",
        "\n",
        "To complete the process, we'll shuffle the combined dataset to ensure the data is randomly mixed. Then, we'll save it to its final file and verify the counts to confirm we have a perfect 1:1 balance."
      ],
      "metadata": {
        "id": "fIR3Gcd_i0pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the final combined DataFrame\n",
        "df_master_sample = df_master_sample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(\"1. Shuffled the master sample.\")\n",
        "\n",
        "# Save the final balanced sample to a new CSV file\n",
        "df_master_sample.to_csv(OUTPUT_FILE, index=False)\n",
        "print(f\"\\n2. Success! Master sample has been saved to '{OUTPUT_FILE}'\")\n",
        "print(\"   You can find this file in the Colab file browser on the left.\")\n",
        "\n",
        "# Verify the final shape and distribution\n",
        "print(f\"\\n   - Final shape of the master sample: {df_master_sample.shape}\")\n",
        "print(f\"\\n   - Final distribution of the target variable:\")\n",
        "print(df_master_sample['target'].value_counts())"
      ],
      "metadata": {
        "id": "w8aINYeJi2Z8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}