{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 6.2. Model Training: XGBoost Classifier\n",
        "\n",
        "This notebook trains the **XGBoost (Extreme Gradient Boosting) Classifier**.\n",
        "\n",
        "XGBoost builds trees *sequentially*. Each new tree is built to correct the errors made by the previous ones, making it more robust and accurate.\n",
        "\n",
        "**Goal:** To see if XGBoost can find more complex patterns in the data and beat the ~66% baseline set by the Logistic Regression model."
      ],
      "metadata": {
        "id": "usI6TsdUyqok"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMu09RuFyfgi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load the Tree-Specific Datasets\n",
        "\n",
        "We will use the `_tree.csv` files."
      ],
      "metadata": {
        "id": "eNO8yevVy0JA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define Output Directory ---\n",
        "OUTPUT_DIR = \"xgboost_results\"\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "    print(f\"Directory '{OUTPUT_DIR}' created.\")\n",
        "\n",
        "# --- Load Data ---\n",
        "try:\n",
        "    X_train = pd.read_csv('X_train_tree.csv')\n",
        "    y_train = pd.read_csv('y_train_tree.csv')\n",
        "    X_test = pd.read_csv('X_test_tree.csv')\n",
        "    y_test = pd.read_csv('y_test_tree.csv')\n",
        "\n",
        "    print(\"All tree-specific training and testing data loaded successfully.\")\n",
        "    print(f\"X_train shape: {X_train.shape}\")\n",
        "    print(f\"X_test shape: {X_test.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Could not find all four _tree.csv files.\")\n",
        "    print(\"Please upload X_train_tree, y_train_tree, X_test_tree, and y_test_tree.\")"
      ],
      "metadata": {
        "id": "dm3hJELQy36Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Initialize and Train the Model\n",
        "\n",
        "We will initialize the `XGBClassifier`.\n",
        "- `n_estimators=100`: Like Random Forest, we'll build 100 trees.\n",
        "- `n_jobs=-1`: Use all available CPU cores to speed up training.\n",
        "- `random_state=42`: For reproducibility."
      ],
      "metadata": {
        "id": "LQyC9kA_y63_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "print(\"Training the XGBoost model...\")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "print(\"Model training complete.\")"
      ],
      "metadata": {
        "id": "7Ql3Rms1y_NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Make Predictions on the Test Data\n",
        "\n",
        "We'll use our new XGBoost model to make predictions on the unseen `X_test_tree` data."
      ],
      "metadata": {
        "id": "x8Aj7LWGy-yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "print(\"Predictions made on the test set.\")"
      ],
      "metadata": {
        "id": "7VGgq6PEzFAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Evaluate Model Performance\n",
        "\n",
        "We generate the full classification report and plot the Confusion Matrix to see if XGBoost performed any better than the 66% F1-score from Logistic Regression."
      ],
      "metadata": {
        "id": "F6hnwMLKzLPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Check the full Classification Report\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "report = classification_report(y_test, predictions, target_names=['Fully Paid (0)', 'Charged Off (1)'])\n",
        "print(report)\n",
        "\n",
        "# Check the Confusion Matrix\n",
        "print(\"\\n--- Confusion Matrix ---\")\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    predictions,\n",
        "    ax=ax,\n",
        "    display_labels=['Fully Paid', 'Charged Off'],\n",
        "    cmap='Purples'\n",
        ")\n",
        "plt.title(\"XGBoost Classifier Confusion Matrix\")\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"xgb_confusion_matrix.png\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yoiKRNrEzNow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Interpret the Model (Feature Importance)\n",
        "\n",
        "XGBoost also provides `.feature_importances_`. This score measures how useful each feature was to the model when making its predictions."
      ],
      "metadata": {
        "id": "bprfBqZmzP_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the feature importances from the trained model\n",
        "importances = model.feature_importances_\n",
        "\n",
        "# Get the feature names\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# Create a DataFrame to see them clearly\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "\n",
        "# Sort by importance\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# --- Save and Display Top 15 ---\n",
        "print(\"--- Top 15 Most Important Features (XGBoost) ---\")\n",
        "display(importance_df.head(15))\n",
        "\n",
        "# Save the full list to a CSV\n",
        "importance_csv_path = os.path.join(OUTPUT_DIR, \"xgb_feature_importances.csv\")\n",
        "importance_df.to_csv(importance_csv_path, index=False)\n",
        "\n",
        "# --- Plot the Top 15 ---\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(\n",
        "    x='Importance',\n",
        "    y='Feature',\n",
        "    data=importance_df.head(15)\n",
        ")\n",
        "plt.title('Top 15 Features (XGBoost)')\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"xgb_feature_importance_plot.png\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4Ig9sGIdzSny"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}