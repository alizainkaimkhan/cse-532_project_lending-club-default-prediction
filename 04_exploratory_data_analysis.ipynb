{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Exploratory Data Analysis (EDA)\n",
        "\n",
        "This notebook performs Exploratory Data Analysis (EDA) on the sampled dataset. The goal is to visualize the relationships between key predictive features and the loan outcome ('Fully Paid' vs. 'Charged Off').\n",
        "\n",
        "The analysis is divided into two main parts:\n",
        "1.  **Bivariate Analysis:** We will plot each key feature (numerical and categorical) against the target variable to see how its distribution changes for good and bad loans. This helps identify the most influential predictors of default.\n",
        "2.  **Multivariate Analysis:** We will create a correlation heatmap to understand the relationships amongst key numerical features."
      ],
      "metadata": {
        "id": "LCkbbLcTqVIA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96l-8ePMqGDL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration and Key Variables\n",
        "\n",
        "Here we define the input file (master sample), the directory where we'll save our plots, and the specific lists of key variables we want to investigate."
      ],
      "metadata": {
        "id": "YEC0aPhmqZoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "INPUT_FILE = 'lc_loans_master_sample.csv'\n",
        "OUTPUT_DIR = 'eda_plots'\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "# --- Define Key Variables for Analysis ---\n",
        "key_numerical_vars = [\n",
        "    'loan_amnt',\n",
        "    'int_rate',\n",
        "    'installment',\n",
        "    'annual_inc',\n",
        "    'dti',\n",
        "    'fico_range_low',\n",
        "    'credit_history_length_days',\n",
        "    'inq_last_6mths'\n",
        "]\n",
        "\n",
        "key_categorical_vars = [\n",
        "    'term',\n",
        "    'grade',\n",
        "    'sub_grade',\n",
        "    'home_ownership',\n",
        "    'purpose'\n",
        "]"
      ],
      "metadata": {
        "id": "QdH8qvSkqeUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load the Master Sample Dataset\n",
        "\n",
        "We'll load the `lc_loans_master_sample.csv` file created in the sampling step and take a quick look at the first few rows."
      ],
      "metadata": {
        "id": "BcQmMxSrqgs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the 'lc_loans_master_sample.csv' file.\n",
        "try:\n",
        "    df = pd.read_csv(INPUT_FILE)\n",
        "    print(\"Master sample dataset loaded successfully.\")\n",
        "    print(f\"Shape of the dataset: {df.shape}\")\n",
        "    display(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{INPUT_FILE}' was not found.\")\n",
        "    print(\"Please make sure you've uploaded the file to this Colab session.\")\n",
        "\n",
        "# Set plot style for all visualizations\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "metadata": {
        "id": "zssvkb_HqivA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Bivariate Analysis (Key Features vs. Target)\n",
        "\n",
        "We will loop through our key variables and create plots to visualize their relationship with the loan outcome. This will help us form hypotheses about which factors are most predictive of default.\n",
        "\n",
        "### Numerical Features vs. Target\n",
        "\n",
        "We'll use box plots to compare the distributions of our key numerical features for 'Fully Paid' loans (target=0) versus 'Charged Off' loans (target=1)."
      ],
      "metadata": {
        "id": "Ew-Bttldqkym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"--- Generating Bivariate Plots for {len(key_numerical_vars)} Key Numerical Variables ---\")\n",
        "\n",
        "for col in key_numerical_vars:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(data=df, x='target', y=col)\n",
        "    plt.title(f'{col.replace(\"_\", \" \").title()} vs. Loan Outcome', fontsize=16)\n",
        "    plt.xticks([0, 1], ['Fully Paid', 'Charged Off'])\n",
        "\n",
        "    # Save the plot to the directory\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, f'bivariate_boxplot_{col}.png'))\n",
        "\n",
        "    # Display the plot directly in the notebook\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "eHxheJ8VqnGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot above is unreadable due to a few extreme outliers in `annual_inc`. To get a better view of the distribution for the majority of borrowers, we create a new plot that filters out the top 1% of incomes."
      ],
      "metadata": {
        "id": "5Qi62cyn-I_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the 99th percentile\n",
        "cutoff = df['annual_inc'].quantile(0.99)\n",
        "\n",
        "# Create a temporary DataFrame for plotting\n",
        "df_filtered = df[df['annual_inc'] < cutoff]\n",
        "\n",
        "# Create the new, \"zoomed-in\" box plot excluding extreme outliers\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df_filtered, x='target', y='annual_inc')\n",
        "plt.title('Annual Income (Excluding Top 1%) vs. Loan Outcome')\n",
        "plt.xticks([0, 1], ['Fully Paid', 'Charged Off'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zESyaXtw-LtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `dti` box plot is also compressed by extreme outliers, including some unexpected negative values and a few very high values. We will create a \"zoomed-in\" plot by filtering the data to show the primary distribution (e.g., from 0 up to a DTI of 100)."
      ],
      "metadata": {
        "id": "7Ol3mVyUeCkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for a reasonable DTI range.\n",
        "# Set the lower limit to 0 as DTI cannot be negative\n",
        "# Set the upper limit to 100 as anything over 100 is an anomly\n",
        "cutoff_low = 0\n",
        "cutoff_high = 100\n",
        "\n",
        "# Create a temporary DataFrame for plotting, filtering out the extremes\n",
        "df_filtered_dti = df[(df['dti'] >= cutoff_low) & (df['dti'] < cutoff_high)]\n",
        "\n",
        "# Create the new, \"zoomed-in\" box plot excluding extreme outliers\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df_filtered_dti, x='target', y='dti')\n",
        "plt.title('DTI (Filtered 0-100) vs. Loan Outcome')\n",
        "plt.xticks([0, 1], ['Fully Paid', 'Charged Off'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Ld0SWSkeFoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categorical Features vs. Target\n",
        "\n",
        "Now we'll use count plots to see how the loan outcomes are distributed across our key categorical features."
      ],
      "metadata": {
        "id": "vke6XJ6cqpT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n--- Generating Bivariate Plots for {len(key_categorical_vars)} Key Categorical Variables ---\")\n",
        "\n",
        "for col in key_categorical_vars:\n",
        "    plt.figure(figsize=(12, 7))\n",
        "\n",
        "    # Use a horizontal plot (y-axis) for categories with many or long labels\n",
        "    if df[col].nunique() > 5:\n",
        "        sns.countplot(data=df, y=col, hue='target', order=sorted(df[col].unique()))\n",
        "    else:\n",
        "        sns.countplot(data=df, x=col, hue='target', order=sorted(df[col].unique()))\n",
        "\n",
        "    plt.title(f'Loan Outcome by {col.replace(\"_\", \" \").title()}', fontsize=16)\n",
        "    plt.legend(title='Outcome', labels=['Fully Paid', 'Charged Off'])\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, f'bivariate_countplot_{col}.png'))\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "0S0IX4DxqsiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Multivariate Analysis (Correlation Between Key Features)\n",
        "\n",
        "Finally, we'll create a correlation heatmap. This helps us understand the relationships between our key numerical features. High correlation between two features (a value close to 1.0 or -1.0) indicates multicollinearity, which can be an issue for some model types."
      ],
      "metadata": {
        "id": "0TkWASx3qu0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Generating Focused Correlation Heatmap ---\")\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "key_numeric_df = df[key_numerical_vars]\n",
        "corr_matrix = key_numeric_df.corr()\n",
        "\n",
        "sns.heatmap(corr_matrix, cmap='viridis', annot=True, fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Key Numerical Features', fontsize=16)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'multivariate_heatmap_key_features.png'))\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(f\"\\n--- Focused EDA Complete. All plots have been saved to the '{OUTPUT_DIR}' directory. ---\")"
      ],
      "metadata": {
        "id": "tdQzsPLNqwjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grade, Sub-Grade, and Interest Rate Relationship\n",
        "\n",
        "Our hypothesis is that the `int_rate` is directly determined by the `sub_grade` assigned to the loan. To confirm this, the following script will load the full **cleaned** dataset, group it by `grade` and `sub_grade`, and then calculate the `mean` interest rate for each group."
      ],
      "metadata": {
        "id": "evmWyN6jn7PE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload 'lc_loans_cleaned.csv' to this Colab session\n",
        "try:\n",
        "    df_cleaned = pd.read_csv('lc_loans_cleaned.csv')\n",
        "    print(\"Full cleaned dataset loaded.\")\n",
        "\n",
        "    # Group by grade and sub_grade, and calculate mean interest rate and the count\n",
        "    grade_analysis = df_cleaned.groupby(['grade', 'sub_grade'])['int_rate'].agg(\n",
        "        mean_int_rate='mean',\n",
        "        count='count'\n",
        "    ).reset_index()\n",
        "\n",
        "    # Format the mean interest rate to two decimal places\n",
        "    grade_analysis['mean_int_rate'] = grade_analysis['mean_int_rate'].map('{:.2f}'.format)\n",
        "\n",
        "    # Set pandas options to display all 35 rows\n",
        "    pd.set_option('display.max_rows', None)\n",
        "\n",
        "    print(\"\\nRelationship between Grade, Sub-Grade, Mean Interest Rate, and Count:\")\n",
        "\n",
        "    # Rename the columns for a cleaner final print\n",
        "    grade_analysis = grade_analysis.rename(columns={\n",
        "        'mean_int_rate': 'Mean Interest Rate',\n",
        "        'count': 'Count'\n",
        "    })\n",
        "\n",
        "    print(grade_analysis.to_string(index=False))\n",
        "\n",
        "    # Reset display options\n",
        "    pd.reset_option('display.max_rows')\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'lc_loans_cleaned.csv' not found.\")\n",
        "    print(\"Please upload the cleaned dataset to this Colab session to run this analysis.\")"
      ],
      "metadata": {
        "id": "3V0UGo0zn9MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r eda_plots.zip eda_plots"
      ],
      "metadata": {
        "id": "vefv-PL6pjBQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}